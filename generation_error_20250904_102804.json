{
  "timestamp": "2025-09-04T10:28:04.356451",
  "prompt_preview": "You are an expert narrative architect. Create a concise, clear plot structure\n    that can be used to craft scenes. Prefer specificity over vagueness.\n\n    Story Overview\n    Title: The Trial Before D",
  "providers_tried": [
    "lmstudio"
  ],
  "all_failures": [
    {
      "provider": "lmstudio",
      "error_type": "Exception",
      "error": "Generation failed on lmstudio: HTTP 404: {\n    \"error\": {\n        \"message\": \"Failed to load model \\\"google/gemma-2-27b\\\". Error: Failed to load model\",\n        \"type\": \"invalid_request_error\",\n        \"param\": \"model\",\n        \"code\": \"model_not_found\"\n    }\n}",
      "timestamp": "2025-09-04T10:28:04.099183",
      "prompt_preview": "You are an expert narrative architect. Create a concise, clear plot structure\n    that can be used to craft scenes. Prefer specificity over vagueness.\n\n    Story Overview\n    Title: The Trial Before D...",
      "traceback": "Traceback (most recent call last):\n  File \"C:\\Users\\sscar\\claude-workspace\\story-engine\\core\\orchestration\\llm_orchestrator.py\", line 456, in generate\n    response = await provider.generate(prompt, **kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\sscar\\claude-workspace\\story-engine\\core\\orchestration\\llm_orchestrator.py\", line 191, in generate\n    raise GenerationError(\n    ...<3 lines>...\n    )\ncore.orchestration.llm_orchestrator.GenerationError: Generation failed on lmstudio: HTTP 404: {\n    \"error\": {\n        \"message\": \"Failed to load model \\\"google/gemma-2-27b\\\". Error: Failed to load model\",\n        \"type\": \"invalid_request_error\",\n        \"param\": \"model\",\n        \"code\": \"model_not_found\"\n    }\n}\n"
    }
  ]
}