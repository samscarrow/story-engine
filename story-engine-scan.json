{
  "summary": {
    "total_findings": 52,
    "by_severity": {
      "high": 16,
      "critical": 16,
      "medium": 17,
      "low": 3
    },
    "by_pattern": {
      "silent_fallback": 12,
      "generic_exception_swallowing": 11,
      "commented_real_code": 2,
      "magic_values": 9,
      "fake_delay": 3,
      "noop_implementation": 7,
      "exception_swallowing": 5,
      "fake_success_response": 2,
      "constant_return_function": 1
    },
    "files_affected": 15
  },
  "top_issues": [
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\character_engine\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    pass",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\character_engine\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate"
    },
    {
      "file": "core\\character_engine\\multi_character_simulation.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 206,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 262,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\story_engine\\iterative_story_system.py",
      "line": 401,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            pass",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\story_engine\\iterative_story_system.py",
      "line": 401,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate"
    }
  ],
  "all_findings": [
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 133:             # Would ping OpenAI API endpoint\n 134:             return True\n 135:         except:\n 136:             return False\n 137: "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 253:                 ) as response:\n 254:                     return response.status == 200\n 255:         except:\n 256:             return False\n 257: "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 133:             # Would ping OpenAI API endpoint\n 134:             return True\n 135:         except:\n 136:             return False\n 137: "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 253:                 ) as response:\n 254:                     return response.status == 200\n 255:         except:\n 256:             return False\n 257: "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 1,
      "pattern": "commented_real_code",
      "severity": "high",
      "snippet": "\"\"\"\nCharacter Simulation Engine v2.0\nProduction-ready implementation with LLM abstraction and error handling\n\"\"\"\n\nimport json\nimport asyncio\nimport logging\nfrom abc import ABC, abstractmethod\nfrom dat",
      "suggestion": "Remove commented code and implement properly",
      "context": "   1: \"\"\"\n   2: Character Simulation Engine v2.0\n   3: Production-ready implementation with LLM abstraction and error handling"
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 65,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": "  63:     \n  64:     def __init__(self):\n  65:         self.call_count = 0\n  66:         \n  67:     async def generate_response(self, "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 73,
      "pattern": "fake_delay",
      "severity": "low",
      "snippet": "asyncio.sleep(0.1)  # Simulate",
      "suggestion": "Remove fake delays, implement real functionality",
      "context": "  71:         \"\"\"Generate mock response based on prompt content\"\"\"\n  72:         self.call_count += 1\n  73:         await asyncio.sleep(0.1)  # Simulate API latency\n  74:         \n  75:         # Parse emphasis from prompt if present"
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 57,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> bool:\n        \"\"\"Check if the LLM service is available\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  55:     \n  56:     @abstractmethod\n  57:     async def health_check(self) -> bool:\n  58:         \"\"\"Check if the LLM service is available\"\"\"\n  59:         pass"
    },
    {
      "file": "core\\character_engine\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n                    pass",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 181:                         if json_start >= 0:\n 182:                             return json.loads(content[json_start:json_end])\n 183:                 except:\n 184:                     pass\n 185:                 "
    },
    {
      "file": "core\\character_engine\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    pass",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 181:                         if json_start >= 0:\n 182:                             return json.loads(content[json_start:json_end])\n 183:                 except:\n 184:                     pass\n 185:                 "
    },
    {
      "file": "core\\character_engine\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate",
      "context": ""
    },
    {
      "file": "core\\character_engine\\multi_character_simulation.py",
      "line": 139,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n                    return None",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 137:                         if json_start >= 0:\n 138:                             return json.loads(content[json_start:json_end])\n 139:                 except:\n 140:                     return None\n 141:                 "
    },
    {
      "file": "core\\character_engine\\multi_character_simulation.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 137:                         if json_start >= 0:\n 138:                             return json.loads(content[json_start:json_end])\n 139:                 except:\n 140:                     return None\n 141:                 "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 139,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 137:                 async with session.get(url, timeout=5) as response:\n 138:                     return response.status == 200\n 139:         except:\n 140:             return False\n 141:     "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 206,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 204:                 async with session.get(url, timeout=5) as response:\n 205:                     return response.status == 200\n 206:         except:\n 207:             return False\n 208:     "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 262,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 260:                 async with session.get(url, timeout=5) as response:\n 261:                     return response.status == 200\n 262:         except:\n 263:             return False\n 264:     "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 137:                 async with session.get(url, timeout=5) as response:\n 138:                     return response.status == 200\n 139:         except:\n 140:             return False\n 141:     "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 206,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 204:                 async with session.get(url, timeout=5) as response:\n 205:                     return response.status == 200\n 206:         except:\n 207:             return False\n 208:     "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 262,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 260:                 async with session.get(url, timeout=5) as response:\n 261:                     return response.status == 200\n 262:         except:\n 263:             return False\n 264:     "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 465,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "tokens=100",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 463:     \n 464:     try:\n 465:         response = await orchestrator.generate(test_prompt, max_tokens=100)\n 466:         print(f\"\\n\ud83d\udcdd Response from {response.provider.value}:\")\n 467:         print(f\"  {response.text[:200]}\")"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 78,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def generate(self, prompt: str, **kwargs) -> LLMResponse:\n        \"\"\"Generate text from prompt\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  76:         \n  77:     @abstractmethod\n  78:     async def generate(self, prompt: str, **kwargs) -> LLMResponse:\n  79:         \"\"\"Generate text from prompt\"\"\"\n  80:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 83,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> bool:\n        \"\"\"Check if provider is available\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  81:     \n  82:     @abstractmethod\n  83:     async def health_check(self) -> bool:\n  84:         \"\"\"Check if provider is available\"\"\"\n  85:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 88,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def format_prompt(self, prompt: str, system: str = None) -> str:\n        \"\"\"Format prompt for specific provider\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  86:     \n  87:     @abstractmethod\n  88:     def format_prompt(self, prompt: str, system: str = None) -> str:\n  89:         \"\"\"Format prompt for specific provider\"\"\"\n  90:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 133,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 131:     def __init__(self, config: LLMConfig):\n 132:         self.config = config\n 133:         self.failure_count = 0\n 134:         self.last_failure: Optional[ProviderFailure] = None\n 135:         "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 543,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "return {\"total\": 0, \"success\": 0, \"failure\": 0}",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 541:         \"\"\"Get statistics about generation history\"\"\"\n 542:         if not self.generation_history:\n 543:             return {\"total\": 0, \"success\": 0, \"failure\": 0}\n 544:         \n 545:         success = sum(1 for h in self.generation_history if h.get('success', False))"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 137,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def generate(self, prompt: str, **kwargs) -> LLMResponse:\n        \"\"\"Generate text from prompt - must return real response or raise exception\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 135:         \n 136:     @abstractmethod\n 137:     async def generate(self, prompt: str, **kwargs) -> LLMResponse:\n 138:         \"\"\"Generate text from prompt - must return real response or raise exception\"\"\"\n 139:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 142,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> Dict[str, Any]:\n        \"\"\"Check provider health - return detailed status\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 140:     \n 141:     @abstractmethod\n 142:     async def health_check(self) -> Dict[str, Any]:\n 143:         \"\"\"Check provider health - return detailed status\"\"\"\n 144:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 147,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def format_prompt(self, prompt: str, system: str = None) -> str:\n        \"\"\"Format prompt for specific provider\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 145:     \n 146:     @abstractmethod\n 147:     def format_prompt(self, prompt: str, system: str = None) -> str:\n 148:         \"\"\"Format prompt for specific provider\"\"\"\n 149:         pass"
    },
    {
      "file": "core\\story_engine\\iterative_story_system.py",
      "line": 401,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            pass",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 399:                 \n 400:                 return current_scenes + new_scenes\n 401:         except:\n 402:             pass\n 403:         "
    },
    {
      "file": "core\\story_engine\\iterative_story_system.py",
      "line": 401,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            pass",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 399:                 \n 400:                 return current_scenes + new_scenes\n 401:         except:\n 402:             pass\n 403:         "
    },
    {
      "file": "core\\story_engine\\iterative_story_system.py",
      "line": 401,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate",
      "context": ""
    },
    {
      "file": "core\\story_engine\\narrative_pipeline.py",
      "line": 225,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            pass",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 223:                 json_end = response.rfind('}') + 1\n 224:                 return json.loads(response[json_start:json_end])\n 225:         except:\n 226:             pass\n 227:         "
    },
    {
      "file": "core\\story_engine\\narrative_pipeline.py",
      "line": 225,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            pass",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 223:                 json_end = response.rfind('}') + 1\n 224:                 return json.loads(response[json_start:json_end])\n 225:         except:\n 226:             pass\n 227:         "
    },
    {
      "file": "core\\story_engine\\narrative_pipeline.py",
      "line": 225,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate",
      "context": ""
    },
    {
      "file": "feedback\\archive\\get_kobold_feedback_balanced.py",
      "line": 229,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "tokens=100",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 227: Be extremely concise. One line each. Focus on high-impact changes.\"\"\"\n 228:     \n 229:     response = await ask_kobold(prompt, max_tokens=300, min_tokens=100)\n 230:     \n 231:     print(response)"
    },
    {
      "file": "feedback\\archive\\get_kobold_feedback_extended.py",
      "line": 300,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "tokens=100",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 298: Provide a complete, actionable roadmap.\"\"\"\n 299:     \n 300:     response = await ask_kobold(prompt, max_tokens=3000, min_tokens=1000)\n 301:     \n 302:     print(response[:1500] + \"...\" if len(response) > 1500 else response)"
    },
    {
      "file": "feedback\\archive\\get_kobold_structured.py",
      "line": 57,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n                        pass",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": "  55:                                 json_text = text[json_start:json_end]\n  56:                                 return json.loads(json_text)\n  57:                     except:\n  58:                         pass\n  59:                     return {\"response\": text}"
    },
    {
      "file": "feedback\\archive\\get_kobold_structured.py",
      "line": 57,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                        pass",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": "  55:                                 json_text = text[json_start:json_end]\n  56:                                 return json.loads(json_text)\n  57:                     except:\n  58:                         pass\n  59:                     return {\"response\": text}"
    },
    {
      "file": "feedback\\archive\\get_kobold_structured.py",
      "line": 57,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate",
      "context": ""
    },
    {
      "file": "tests\\archive\\dramatic_emotional_journey.py",
      "line": 20,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": "  18:     def __init__(self):\n  19:         super().__init__()\n  20:         self.scene_count = 0\n  21:         \n  22:     async def generate_response(self, prompt, temperature=0.7, max_tokens=500):"
    },
    {
      "file": "tests\\archive\\gemma2_only_simulation.py",
      "line": 60,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except json.JSONDecodeError:\n            return None",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": "  58:             return None\n  59:             \n  60:         except json.JSONDecodeError:\n  61:             return None\n  62:     "
    },
    {
      "file": "tests\\archive\\launch_kobold_and_test.py",
      "line": 25,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            pass",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": "  23:                         print(\"\u2705 KoboldCpp server is ready!\")\n  24:                         return True\n  25:         except:\n  26:             pass\n  27:         "
    },
    {
      "file": "tests\\archive\\launch_kobold_and_test.py",
      "line": 25,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            pass",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": "  23:                         print(\"\u2705 KoboldCpp server is ready!\")\n  24:                         return True\n  25:         except:\n  26:             pass\n  27:         "
    },
    {
      "file": "tests\\archive\\launch_kobold_and_test.py",
      "line": 25,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate",
      "context": ""
    },
    {
      "file": "tests\\archive\\real_llm_emotional_sequence.py",
      "line": 111,
      "pattern": "commented_real_code",
      "severity": "high",
      "snippet": "# Enhanced MockLLM for more realistic behavior\n    class SequenceMockLLM(Mock",
      "suggestion": "Remove commented code and implement properly",
      "context": " 109:     print(\"\ud83d\udd04 Using Enhanced MockLLM with realistic responses...\")\n 110:     \n 111:     # Enhanced MockLLM for more realistic behavior\n 112:     class SequenceMockLLM(MockLLM):\n 113:         def __init__(self):"
    },
    {
      "file": "tests\\archive\\real_llm_emotional_sequence.py",
      "line": 119,
      "pattern": "fake_delay",
      "severity": "low",
      "snippet": "asyncio.sleep(0.1)  # Simulate",
      "suggestion": "Remove fake delays, implement real functionality",
      "context": " 117:         async def generate_response(self, prompt, temperature=0.7, max_tokens=500):\n 118:             self.call_count += 1\n 119:             await asyncio.sleep(0.1)  # Simulate network delay\n 120:             \n 121:             # Extract context from prompt"
    },
    {
      "file": "tests\\archive\\test_character_simulation.py",
      "line": 263,
      "pattern": "fake_success_response",
      "severity": "high",
      "snippet": "return \"success\"",
      "suggestion": "Return actual operation status, not assumed success",
      "context": " 261:         \"\"\"Test successful execution on first try\"\"\"\n 262:         async def success_func():\n 263:             return \"success\"\n 264:         \n 265:         async def test():"
    },
    {
      "file": "tests\\archive\\test_character_simulation.py",
      "line": 281,
      "pattern": "fake_success_response",
      "severity": "high",
      "snippet": "return \"success\"",
      "suggestion": "Return actual operation status, not assumed success",
      "context": " 279:             if call_count < 3:\n 280:                 raise Exception(\"Test failure\")\n 281:             return \"success\"\n 282:         \n 283:         async def test():"
    },
    {
      "file": "tests\\archive\\test_character_simulation.py",
      "line": 274,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 272:     def test_retry_on_failure(self):\n 273:         \"\"\"Test retry logic on failures\"\"\"\n 274:         call_count = 0\n 275:         \n 276:         async def failing_func():"
    },
    {
      "file": "tests\\archive\\test_character_simulation.py",
      "line": 401,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 399:             \n 400:             # Track concurrent executions\n 401:             concurrent_count = 0\n 402:             max_concurrent = 0\n 403:             "
    },
    {
      "file": "tests\\archive\\test_character_simulation.py",
      "line": 408,
      "pattern": "fake_delay",
      "severity": "low",
      "snippet": "asyncio.sleep(0.1)  # Simulate",
      "suggestion": "Remove fake delays, implement real functionality",
      "context": " 406:                 concurrent_count += 1\n 407:                 max_concurrent = max(max_concurrent, concurrent_count)\n 408:                 await asyncio.sleep(0.1)  # Simulate work\n 409:                 concurrent_count -= 1\n 410:                 return LLMResponse(json.dumps({\"test\": \"response\"}))"
    },
    {
      "file": "tests\\archive\\test_character_simulation.py",
      "line": 262,
      "pattern": "constant_return_function",
      "severity": "medium",
      "snippet": "Function 'success_func' always returns constant",
      "suggestion": "Functions should compute values, not return constants",
      "context": ""
    }
  ]
}