{
  "summary": {
    "total_findings": 41,
    "by_severity": {
      "high": 9,
      "critical": 8,
      "medium": 22,
      "low": 2
    },
    "by_pattern": {
      "silent_fallback": 7,
      "generic_exception_swallowing": 7,
      "commented_real_code": 2,
      "magic_values": 8,
      "fake_delay": 2,
      "noop_implementation": 14,
      "exception_swallowing": 1
    },
    "files_affected": 8
  },
  "top_issues": [
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    pass",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate"
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 206,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 262,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\multi_character_simulation.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    return",
      "suggestion": "Catch specific exceptions and handle them appropriately"
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data"
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data"
    }
  ],
  "all_findings": [
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 133:             # Would ping OpenAI API endpoint\n 134:             return True\n 135:         except:\n 136:             return False\n 137: "
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 253:                 ) as response:\n 254:                     return response.status == 200\n 255:         except:\n 256:             return False\n 257: "
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 135,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 133:             # Would ping OpenAI API endpoint\n 134:             return True\n 135:         except:\n 136:             return False\n 137: "
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 255,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 253:                 ) as response:\n 254:                     return response.status == 200\n 255:         except:\n 256:             return False\n 257: "
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 1,
      "pattern": "commented_real_code",
      "severity": "high",
      "snippet": "\"\"\"\nCharacter Simulation Engine v2.0\nProduction-ready implementation with LLM abstraction and error handling\n\"\"\"\n\nimport json\nimport asyncio\nimport logging\nfrom abc import ABC, abstractmethod\nfrom dat",
      "suggestion": "Remove commented code and implement properly",
      "context": "   1: \"\"\"\n   2: Character Simulation Engine v2.0\n   3: Production-ready implementation with LLM abstraction and error handling"
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 65,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": "  63:     \n  64:     def __init__(self):\n  65:         self.call_count = 0\n  66:         \n  67:     async def generate_response(self, "
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 73,
      "pattern": "fake_delay",
      "severity": "low",
      "snippet": "asyncio.sleep(0.1)  # Simulate",
      "suggestion": "Remove fake delays, implement real functionality",
      "context": "  71:         \"\"\"Generate mock response based on prompt content\"\"\"\n  72:         self.call_count += 1\n  73:         await asyncio.sleep(0.1)  # Simulate API latency\n  74:         \n  75:         # Parse emphasis from prompt if present"
    },
    {
      "file": "core\\archive\\character_simulation_engine_v2.py",
      "line": 57,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> bool:\n        \"\"\"Check if the LLM service is available\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  55:     \n  56:     @abstractmethod\n  57:     async def health_check(self) -> bool:\n  58:         \"\"\"Check if the LLM service is available\"\"\"\n  59:         pass"
    },
    {
      "file": "core\\archive\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n                    pass",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 181:                         if json_start >= 0:\n 182:                             return json.loads(content[json_start:json_end])\n 183:                 except:\n 184:                     pass\n 185:                 "
    },
    {
      "file": "core\\archive\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    pass",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 181:                         if json_start >= 0:\n 182:                             return json.loads(content[json_start:json_end])\n 183:                 except:\n 184:                     pass\n 185:                 "
    },
    {
      "file": "core\\archive\\complex_group_dynamics.py",
      "line": 183,
      "pattern": "exception_swallowing",
      "severity": "critical",
      "snippet": "except: pass",
      "suggestion": "Handle exceptions properly or let them propagate",
      "context": ""
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 139,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 137:                 async with session.get(url, timeout=5) as response:\n 138:                     return response.status == 200\n 139:         except:\n 140:             return False\n 141:     "
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 206,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 204:                 async with session.get(url, timeout=5) as response:\n 205:                     return response.status == 200\n 206:         except:\n 207:             return False\n 208:     "
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 262,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n            return False",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 260:                 async with session.get(url, timeout=5) as response:\n 261:                     return response.status == 200\n 262:         except:\n 263:             return False\n 264:     "
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 137:                 async with session.get(url, timeout=5) as response:\n 138:                     return response.status == 200\n 139:         except:\n 140:             return False\n 141:     "
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 206,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 204:                 async with session.get(url, timeout=5) as response:\n 205:                     return response.status == 200\n 206:         except:\n 207:             return False\n 208:     "
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 262,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n            return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 260:                 async with session.get(url, timeout=5) as response:\n 261:                     return response.status == 200\n 262:         except:\n 263:             return False\n 264:     "
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 465,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "tokens=100",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 463:     \n 464:     try:\n 465:         response = await orchestrator.generate(test_prompt, max_tokens=100)\n 466:         print(f\"\\n\ud83d\udcdd Response from {response.provider.value}:\")\n 467:         print(f\"  {response.text[:200]}\")"
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 78,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def generate(self, prompt: str, **kwargs) -> LLMResponse:\n        \"\"\"Generate text from prompt\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  76:         \n  77:     @abstractmethod\n  78:     async def generate(self, prompt: str, **kwargs) -> LLMResponse:\n  79:         \"\"\"Generate text from prompt\"\"\"\n  80:         pass"
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 83,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> bool:\n        \"\"\"Check if provider is available\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  81:     \n  82:     @abstractmethod\n  83:     async def health_check(self) -> bool:\n  84:         \"\"\"Check if provider is available\"\"\"\n  85:         pass"
    },
    {
      "file": "core\\archive\\llm_orchestrator_old.py",
      "line": 88,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def format_prompt(self, prompt: str, system: str = None) -> str:\n        \"\"\"Format prompt for specific provider\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  86:     \n  87:     @abstractmethod\n  88:     def format_prompt(self, prompt: str, system: str = None) -> str:\n  89:         \"\"\"Format prompt for specific provider\"\"\"\n  90:         pass"
    },
    {
      "file": "core\\archive\\multi_character_simulation.py",
      "line": 139,
      "pattern": "silent_fallback",
      "severity": "high",
      "snippet": "except:\n                    return None",
      "suggestion": "Throw explicit errors instead of silently returning fallback data",
      "context": " 137:                         if json_start >= 0:\n 138:                             return json.loads(content[json_start:json_end])\n 139:                 except:\n 140:                     return None\n 141:                 "
    },
    {
      "file": "core\\archive\\multi_character_simulation.py",
      "line": 139,
      "pattern": "generic_exception_swallowing",
      "severity": "critical",
      "snippet": "except:\n                    return",
      "suggestion": "Catch specific exceptions and handle them appropriately",
      "context": " 137:                         if json_start >= 0:\n 138:                             return json.loads(content[json_start:json_end])\n 139:                 except:\n 140:                     return None\n 141:                 "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 1,
      "pattern": "commented_real_code",
      "severity": "high",
      "snippet": "\"\"\"\nCharacter Simulation Engine v2.0\nProduction-ready implementation with LLM abstraction and error handling\n\"\"\"\n\nimport json\nimport asyncio\nimport logging\nfrom abc import ABC, abstractmethod\nfrom dat",
      "suggestion": "Remove commented code and implement properly",
      "context": "   1: \"\"\"\n   2: Character Simulation Engine v2.0\n   3: Production-ready implementation with LLM abstraction and error handling"
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 65,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": "  63:     \n  64:     def __init__(self):\n  65:         self.call_count = 0\n  66:         \n  67:     async def generate_response(self, "
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 73,
      "pattern": "fake_delay",
      "severity": "low",
      "snippet": "asyncio.sleep(0.1)  # Simulate",
      "suggestion": "Remove fake delays, implement real functionality",
      "context": "  71:         \"\"\"Generate mock response based on prompt content\"\"\"\n  72:         self.call_count += 1\n  73:         await asyncio.sleep(0.1)  # Simulate API latency\n  74:         \n  75:         # Parse emphasis from prompt if present"
    },
    {
      "file": "core\\character_engine\\character_simulation_engine_v2.py",
      "line": 57,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> bool:\n        \"\"\"Check if the LLM service is available\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  55:     \n  56:     @abstractmethod\n  57:     async def health_check(self) -> bool:\n  58:         \"\"\"Check if the LLM service is available\"\"\"\n  59:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 480,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "tokens=100",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 478:     \n 479:     try:\n 480:         response = await orchestrator.generate(test_prompt, max_tokens=100)\n 481:         print(f\"\\n\ud83d\udcdd Response from {response.provider.value}:\")\n 482:         print(f\"  {response.text[:200]}\")"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 78,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def generate(self, prompt: str, **kwargs) -> LLMResponse:\n        \"\"\"Generate text from prompt\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  76:         \n  77:     @abstractmethod\n  78:     async def generate(self, prompt: str, **kwargs) -> LLMResponse:\n  79:         \"\"\"Generate text from prompt\"\"\"\n  80:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 83,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> bool:\n        \"\"\"Check if provider is available\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  81:     \n  82:     @abstractmethod\n  83:     async def health_check(self) -> bool:\n  84:         \"\"\"Check if provider is available\"\"\"\n  85:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator.py",
      "line": 88,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def format_prompt(self, prompt: str, system: str = None) -> str:\n        \"\"\"Format prompt for specific provider\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": "  86:     \n  87:     @abstractmethod\n  88:     def format_prompt(self, prompt: str, system: str = None) -> str:\n  89:         \"\"\"Format prompt for specific provider\"\"\"\n  90:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_fixed.py",
      "line": 133,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 131:     def __init__(self, config: LLMConfig):\n 132:         self.config = config\n 133:         self.failure_count = 0\n 134:         self.last_failure: Optional[ProviderFailure] = None\n 135:         "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_fixed.py",
      "line": 543,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "return {\"total\": 0, \"success\": 0, \"failure\": 0}",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 541:         \"\"\"Get statistics about generation history\"\"\"\n 542:         if not self.generation_history:\n 543:             return {\"total\": 0, \"success\": 0, \"failure\": 0}\n 544:         \n 545:         success = sum(1 for h in self.generation_history if h.get('success', False))"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_fixed.py",
      "line": 137,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def generate(self, prompt: str, **kwargs) -> LLMResponse:\n        \"\"\"Generate text from prompt - must return real response or raise exception\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 135:         \n 136:     @abstractmethod\n 137:     async def generate(self, prompt: str, **kwargs) -> LLMResponse:\n 138:         \"\"\"Generate text from prompt - must return real response or raise exception\"\"\"\n 139:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_fixed.py",
      "line": 142,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> Dict[str, Any]:\n        \"\"\"Check provider health - return detailed status\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 140:     \n 141:     @abstractmethod\n 142:     async def health_check(self) -> Dict[str, Any]:\n 143:         \"\"\"Check provider health - return detailed status\"\"\"\n 144:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_fixed.py",
      "line": 147,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def format_prompt(self, prompt: str, system: str = None) -> str:\n        \"\"\"Format prompt for specific provider\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 145:     \n 146:     @abstractmethod\n 147:     def format_prompt(self, prompt: str, system: str = None) -> str:\n 148:         \"\"\"Format prompt for specific provider\"\"\"\n 149:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 133,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "count = 0",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 131:     def __init__(self, config: LLMConfig):\n 132:         self.config = config\n 133:         self.failure_count = 0\n 134:         self.last_failure: Optional[ProviderFailure] = None\n 135:         "
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 543,
      "pattern": "magic_values",
      "severity": "medium",
      "snippet": "return {\"total\": 0, \"success\": 0, \"failure\": 0}",
      "suggestion": "Use actual calculated values or meaningful constants",
      "context": " 541:         \"\"\"Get statistics about generation history\"\"\"\n 542:         if not self.generation_history:\n 543:             return {\"total\": 0, \"success\": 0, \"failure\": 0}\n 544:         \n 545:         success = sum(1 for h in self.generation_history if h.get('success', False))"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 137,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def generate(self, prompt: str, **kwargs) -> LLMResponse:\n        \"\"\"Generate text from prompt - must return real response or raise exception\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 135:         \n 136:     @abstractmethod\n 137:     async def generate(self, prompt: str, **kwargs) -> LLMResponse:\n 138:         \"\"\"Generate text from prompt - must return real response or raise exception\"\"\"\n 139:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 142,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def health_check(self) -> Dict[str, Any]:\n        \"\"\"Check provider health - return detailed status\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 140:     \n 141:     @abstractmethod\n 142:     async def health_check(self) -> Dict[str, Any]:\n 143:         \"\"\"Check provider health - return detailed status\"\"\"\n 144:         pass"
    },
    {
      "file": "core\\orchestration\\llm_orchestrator_strict.py",
      "line": 147,
      "pattern": "noop_implementation",
      "severity": "medium",
      "snippet": "def format_prompt(self, prompt: str, system: str = None) -> str:\n        \"\"\"Format prompt for specific provider\"\"\"\n        pass",
      "suggestion": "Implement the function or raise NotImplementedError",
      "context": " 145:     \n 146:     @abstractmethod\n 147:     def format_prompt(self, prompt: str, system: str = None) -> str:\n 148:         \"\"\"Format prompt for specific provider\"\"\"\n 149:         pass"
    }
  ]
}